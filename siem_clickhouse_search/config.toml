# SIEM ClickHouse Search Service Configuration
# High-performance log search with multi-tenant support

[server]
# HTTP server configuration
host = "0.0.0.0"              # Server bind address
port = 8084                    # Server port (different from main SIEM to avoid conflicts)
workers = 4                    # Number of worker threads
max_connections = 1000         # Maximum concurrent connections
request_timeout_secs = 30      # Request timeout in seconds
keep_alive_timeout_secs = 75   # Keep-alive timeout
max_request_size = 10          # Maximum request size in MB
enable_cors = true             # Enable CORS
cors_origins = ["*"]           # Allowed CORS origins

[clickhouse]
# ClickHouse database configuration
url = "http://localhost:8123"   # ClickHouse HTTP interface URL
host = "localhost"             # ClickHouse server host
port = 9000                    # ClickHouse native port
database = "dev"               # Database name (changed to connect to existing dev.events table)
username = "default"           # Username
password = ""                  # Password (empty for default)
compress = true                # Enable compression
ssl = false                    # Enable SSL/TLS

# Connection pool configuration
[clickhouse.pool]
max_size = 20                  # Maximum number of connections in the pool
min_idle = 5                   # Minimum number of connections to maintain
connection_timeout_secs = 30   # Connection timeout in seconds
max_lifetime_secs = 3600       # Maximum lifetime of a connection in seconds
idle_timeout_secs = 600        # Idle timeout for connections in seconds
health_check_interval_secs = 60 # Health check interval in seconds

# Query configuration
[clickhouse.query]
default_timeout_secs = 60      # Default query timeout in seconds
max_timeout_secs = 300         # Maximum query timeout in seconds
default_page_size = 100        # Default page size for search results
max_page_size = 1000           # Maximum page size allowed
max_concurrent_queries_per_tenant = 10 # Maximum concurrent queries per tenant
enable_caching = true          # Enable query result caching
cache_ttl_secs = 300           # Cache TTL in seconds
max_memory_usage = 10000000000 # Maximum memory usage per query (10GB)
enable_optimization = true     # Enable query optimization

# Table configuration
[clickhouse.tables]
default_table = "events"       # Use existing events table
tenant_table_pattern = "events_{tenant_id}" # Pattern for tenant-specific tables
auto_create_tables = false     # Don't create tables, use existing dev.events

# Partition configuration
[clickhouse.tables.partition]
time_interval = "monthly"      # Monthly partitioning
retention_days = 90           # 90 days retention
auto_prune = true             # Enable automatic pruning

# ClickHouse performance tuning
[clickhouse.performance]
max_threads = 8                # Maximum threads per query
max_block_size = 65536         # Maximum block size
max_insert_block_size = 1048576 # Maximum insert block size
use_uncompressed_cache = true  # Use uncompressed cache
load_balancing = "random"      # Load balancing strategy

[security]
# Security and authentication configuration
enable_tenant_isolation = true                    # Enable multi-tenant isolation
jwt_secret = "your-super-secret-jwt-key-here-change-this-in-production" # JWT signing secret (min 32 chars)
token_expiration_secs = 3600                      # JWT token expiration (1 hour)
enable_rate_limiting = true                       # Enable rate limiting
rate_limit_per_tenant = 1000                      # Requests per minute per tenant
enable_audit_logging = true                       # Enable audit logging
allowed_tenants = []                              # Allowed tenant IDs (empty = all allowed)

# Additional security settings
[security.advanced]
enable_ip_whitelist = false                       # Enable IP whitelisting
allowed_ips = []                                  # Allowed IP addresses/ranges
max_login_attempts = 5                            # Maximum login attempts
lockout_duration_secs = 900                       # Account lockout duration (15 minutes)
enable_2fa = false                                # Enable two-factor authentication
session_timeout_secs = 28800                      # Session timeout (8 hours)

[search]
# Search behavior configuration
enable_fulltext = true                            # Enable full-text search
enable_regex = true                               # Enable regex search
max_regex_complexity = 1000                       # Maximum regex complexity score
enable_streaming = true                           # Enable search result streaming
streaming_chunk_size = 1000                       # Streaming chunk size
enable_analytics = true                           # Enable search analytics
ranking_algorithm = "relevance"                   # Search result ranking algorithm
enable_suggestions = true                         # Enable search suggestions

# Search performance tuning
[search.performance]
enable_parallel_processing = true                 # Enable parallel query processing
max_parallel_queries = 10                         # Maximum parallel queries per request
enable_query_optimization = true                  # Enable automatic query optimization
use_materialized_views = true                     # Use materialized views for common queries
enable_result_streaming = true                    # Enable result streaming for large datasets
stream_buffer_size = 10000                        # Stream buffer size

# Full-text search configuration
[search.fulltext]
enable_fulltext_search = true                     # Enable full-text search capabilities
min_search_length = 3                             # Minimum search term length
max_search_terms = 20                             # Maximum number of search terms
enable_fuzzy_search = true                        # Enable fuzzy/approximate matching
fuzzy_distance = 2                                # Maximum edit distance for fuzzy search
enable_regex_search = true                        # Enable regex search
max_regex_complexity = 1000                       # Maximum regex complexity

[redis]
# Redis configuration for caching
url = "redis://localhost:6379/1"  # Redis connection URL
pool_size = 20                     # Connection pool size
connection_timeout_secs = 5        # Connection timeout in seconds
default_ttl_secs = 3600           # Default TTL for cached items in seconds
max_cache_size = 1073741824       # Maximum cache size in bytes (1GB)
enable_compression = true          # Enable cache compression

# Redis clustering (if using Redis Cluster)
[redis.cluster]
enable_cluster = false         # Enable Redis Cluster mode
nodes = []                     # Cluster node addresses
read_from_replicas = true      # Allow reading from replica nodes

[monitoring]
# Monitoring and observability
enable_metrics = true                    # Enable Prometheus metrics
metrics_path = "/metrics"                # Metrics endpoint path
enable_health_check = true               # Enable health check endpoint
health_check_path = "/health"            # Health check endpoint path
enable_performance_monitoring = true     # Enable performance monitoring
performance_interval_secs = 60           # Performance metrics collection interval in seconds
enable_query_logging = true              # Enable query logging
slow_query_threshold_ms = 5000           # Log slow queries threshold in milliseconds

# Metrics collection intervals
[monitoring.intervals]
metrics_collection_secs = 30   # Metrics collection interval
health_check_secs = 60         # Health check interval
performance_stats_secs = 300   # Performance statistics interval

[retention]
# Data retention policies
enable_retention = true        # Enable automatic data retention
default_retention_days = 90    # Default retention period in days
max_retention_days = 365       # Maximum retention period

# Tenant-specific retention (optional)
[retention.tenants]
# tenant1 = 30                 # Custom retention for tenant1 (30 days)
# tenant2 = 180                # Custom retention for tenant2 (180 days)

[detection]
# Detection rules integration
enable_detection_rules = true  # Enable detection rules during search
rules_cache_ttl_secs = 600     # Rules cache TTL (10 minutes)
max_rules_per_query = 50       # Maximum rules to apply per query
enable_rule_performance_tracking = true # Track rule performance

# Rule execution settings
[detection.execution]
max_rule_execution_time_ms = 1000 # Maximum rule execution time
enable_parallel_rule_execution = true # Enable parallel rule execution
rule_timeout_action = "skip"   # Action on rule timeout (skip, fail, warn)

[api]
# API configuration
enable_swagger = true          # Enable Swagger/OpenAPI documentation
swagger_path = "/docs"         # Swagger UI path
enable_cors = true             # Enable CORS
cors_origins = ["*"]           # Allowed CORS origins
max_request_size_mb = 10       # Maximum request size in MB
enable_compression = true      # Enable response compression

# API versioning
[api.versioning]
enable_versioning = true       # Enable API versioning
default_version = "v1"         # Default API version
supported_versions = ["v1"]    # Supported API versions

[features]
# Feature flags
enable_experimental_features = false # Enable experimental features
enable_advanced_analytics = true     # Enable advanced analytics
enable_machine_learning = false      # Enable ML-based features
enable_graph_queries = false         # Enable graph-based queries
enable_time_series_analysis = true   # Enable time series analysis

# Experimental features (when enabled)
[features.experimental]
enable_auto_indexing = false         # Automatic index creation
enable_query_suggestions = false     # Query auto-completion
enable_anomaly_detection = false     # Real-time anomaly detection
enable_predictive_caching = false    # Predictive result caching

[backup]
# Backup and disaster recovery
enable_backup = false          # Enable automatic backups
backup_interval_hours = 24     # Backup interval in hours
backup_retention_days = 30     # Backup retention period
backup_location = "/var/backups/siem" # Backup storage location
enable_incremental_backup = true # Enable incremental backups

[development]
# Development and debugging settings
enable_debug_mode = false      # Enable debug mode
enable_query_profiling = false # Enable query profiling
enable_memory_profiling = false # Enable memory profiling
enable_hot_reload = false      # Enable configuration hot reload
log_queries = false            # Log all executed queries
log_query_plans = false        # Log query execution plans

# Performance testing
[development.testing]
enable_load_testing = false    # Enable built-in load testing
test_data_size = 1000000       # Test data size for benchmarks
enable_chaos_testing = false   # Enable chaos engineering features

# Example tenant configurations
# Uncomment and modify as needed

# [tenants.tenant1]
# name = "Organization 1"
# retention_days = 90
# max_queries_per_minute = 500
# allowed_fields = ["*"]
# restricted_fields = []
# custom_indexes = ["source_ip", "user_id"]

# [tenants.tenant2]
# name = "Organization 2"
# retention_days = 180
# max_queries_per_minute = 1000
# allowed_fields = ["*"]
# restricted_fields = ["sensitive_data"]
# custom_indexes = ["event_type", "severity"]

# Database schema configuration
[schema]
# Table and column configurations
table_name = "events"          # Main events table name
partition_by = "toYYYYMM(timestamp)" # Partitioning strategy
order_by = "(tenant_id, timestamp, event_id)" # Ordering key
ttl_expression = "timestamp + INTERVAL 90 DAY" # TTL expression

# Column mappings
[schema.columns]
timestamp = "timestamp"        # Timestamp column
tenant_id = "tenant_id"        # Tenant ID column
event_id = "event_id"          # Event ID column
source_ip = "source_ip"        # Source IP column
destination_ip = "dest_ip"     # Destination IP column
event_type = "event_type"      # Event type column
severity = "severity"          # Severity column
message = "message"            # Message column
raw_log = "raw_log"            # Raw log column
metadata = "metadata"          # Metadata column (JSON)

# Index configurations
[schema.indexes]
# Automatically created indexes
auto_indexes = [
    "tenant_id",
    "timestamp",
    "event_type",
    "severity",
    "source_ip"
]

# Custom indexes for specific use cases
custom_indexes = [
    # "(tenant_id, event_type, timestamp)",
    # "(source_ip, destination_ip)",
    # "(user_id, timestamp)"
]

# Materialized views for common queries
[schema.materialized_views]
enable_materialized_views = true
views = [
    # "hourly_event_counts",
    # "daily_ip_statistics",
    # "security_events_summary"
]