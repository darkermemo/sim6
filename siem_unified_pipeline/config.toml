[server]
host = "0.0.0.0"
port = 9999
workers = 4
max_connections = 1000
request_timeout = 30
enable_cors = true

# Feature Flags Configuration
[features]
enable_kafka = false
enable_vector = true
enable_redis = false
enable_ch_sse = true

# Database Configuration (ClickHouse)
[database]
host = "localhost"
port = 8123
database = "dev"
username = "default"
password = ""
max_connections = 20
min_connections = 5
connection_timeout = 30
idle_timeout = 600
max_lifetime = 3600

# Data Sources Configuration
[sources.syslog_source]
source_type = { type = "syslog", port = 5142, protocol = "udp" }
enabled = false
batch_size = 1000
buffer_size = 10000
retry_attempts = 3
retry_delay = 1000

[sources.syslog_source.config]
format = "syslog"
encoding = "utf-8"
fields = {}

# Transformations Configuration
[transformations.basic_transform]
parallel = false
error_handling = "continue"

[[transformations.basic_transform.steps]]
type = "parse"
parser = "json"
config = {}

# Storage Configuration
[storage]

[storage.data_lake]
provider = "minio"
bucket = "siem-data-lake"
region = "us-east-1"
access_key = "minioadmin"
secret_key = "minioadmin"
endpoint = "http://localhost:9000"

[storage.hot_storage]
clickhouse_url = "tcp://localhost:9000/default"
database = "siem"
retention_days = 30

[storage.cold_storage]
s3_bucket = "siem-cold-storage"
compression = "zstd"
format = "parquet"
s3_region = "us-east-1"
s3_access_key = "minioadmin"
s3_secret_key = "minioadmin"

[storage.retention]
hot_days = 7
warm_days = 30
cold_days = 365
delete_after_days = 2555
retention_days = 365

[security]
# TLS configuration (optional)
# [security.tls]
# cert_file = "/path/to/cert.pem"
# key_file = "/path/to/key.pem"
# ca_file = "/path/to/ca.pem"

# Authentication configuration (optional)
# [security.authentication]
# method = "ApiKey"
# [security.authentication.config]
# api_key = "your-api-key"

# Rate limiting configuration (optional)
# [security.rate_limiting]
# requests_per_second = 1000
# burst_size = 100
# window_seconds = 60

[routing]
default_destination = "redis_cache"
load_balancing = "round_robin"

[[routing.rules]]
name = "all_events"
condition = "true"
destinations = ["redis_cache"]
priority = 1
enabled = true

[destinations.redis_cache]
enabled = true
batch_size = 1000
flush_interval = 5000
retry_attempts = 3

[destinations.redis_cache.destination_type]
type = "redis"
connection_string = "redis://localhost:6379/0"
key_pattern = "siem:events:{timestamp}:{source}"
ttl = 3600

[destinations.redis_cache.config]
format = "json"
compression = "gzip"

# ClickHouse destination for analytics and long-term storage
[destinations.clickhouse_main]
enabled = true
batch_size = 1000
flush_interval = 5000
retry_attempts = 3

[destinations.clickhouse_main.destination_type]
type = "click_house"
connection_string = "http://localhost:8123"
database = "dev"
table = "events"

[destinations.clickhouse_main.config]
format = "json"
compression = "lz4"

# Kafka destination for real-time streaming
[destinations.kafka_stream]
enabled = true
batch_size = 1000
flush_interval = 5000
retry_attempts = 3

[destinations.kafka_stream.destination_type]
type = "kafka"
brokers = ["localhost:9092"]
topic = "siem-events"

[destinations.kafka_stream.config]
format = "json"
compression = "gzip"



[metrics]
enabled = true
port = 9090
path = "/metrics"
labels = {}

[performance]
[performance.workers]
ingestion_workers = 4
transformation_workers = 8
routing_workers = 4
storage_workers = 8

[performance.buffers]
event_buffer_size = 100000
batch_buffer_size = 10000
flush_interval_ms = 1000

[performance.memory]
max_memory_usage = "8GB"
gc_threshold = "6GB"

[performance.parallel_processing]
enabled = false
worker_count = 4
batch_size = 1000
batch_timeout_ms = 100

[rate_limiting]
enabled = true
requests_per_second = 1000
burst_size = 5000

# Vector Configuration
[vector]
enabled = true
base_url = "http://127.0.0.1:8686"
health_path = "/health"
metrics_path = "/metrics"
timeout_ms = 5000